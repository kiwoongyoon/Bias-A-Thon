# 🏆 2025 Bias-A-Thon Track 2

---

## 📊 대회 개요

* **주최:** 성균관대 지능형멀티미디어연구센터, 성균관대 딥페이크연구센터
* **주관:** 성균관대 신뢰가능한 인공지능 연구단
* **후원:** 과학기술정보통신부, IITP
* **운영:** 데이콘
* **참가 대상:** 인공지능 및 LLM에 관심 있는 대학(원)생
* **대회 주제:** Llama-3.1-8B-Instruct 모델을 이용하여 다양한 편향 상황에서 공정하고 균형 잡힌 응답을 생성하는 프롬프트 및 RAG 기법 개발

---

## 📂 목차

1. [대회 개요](#대회-개요)
2. [데이터 처리(마스킹)](#데이터-처리마스킹)
3. [추론 전략(QA)](#추론-전략qa)
4. [시도한 방안들](#시도한-방안들)
5. [결론 및 느낀점](#결론-및-느낀점)

---

## 1. 대회 개요

최근 LLM의 발전으로 인해 나타나는 다양한 사회적 편향을 진단하고, 공정하고 중립적인 응답을 생성하는 전략을 탐구하는 대회입니다.

* **모델 제한:** Llama-3.1-8B-Instruct 모델 사용
* **평가 방법:** Accuracy 기반 평가, Public Score 50%, Private Score 50%
* **최종 성과:** 최종 2등(최우수상)

---

## 2. 데이터 처리(마스킹)

편향 문제 해결을 위해 데이터에 대한 전략적인 마스킹을 적용했습니다.

* 성별 표현(남성, 남자 등) 일관성 확보
* `choices`에 주어진 선택지를 이용한 1차 마스킹
* 정규식으로 처리되지 않는 샘플에 대해 LLM 기반 few-shot 마스킹 적용
* 마스킹 태그 미포함 문장 제거로 불필요한 정보 및 토큰 개수 축소

---

## 3. 추론 전략(QA)

응답의 안정성과 정확성을 높이기 위한 다양한 전략을 채택했습니다.

* SamplingParams 조정으로 결정론적이고 신뢰할 수 있는 응답 유도
* context, question, choices의 등장 순서를 변경하여 편향된 응답 예방
* 한국 소설 발췌를 few-shot으로 활용해 정확한 문맥 인지를 모델에 강조
* entity 태그를 서로 맞바꿔서 편향된 태그 순서 문제 해결 및 데이터 다양화 효과 창출

---

## 4. 시도한 방안들

편향 저감을 위해 다양한 접근을 시도했습니다.

* 반대 의미의 질문, 다양한 '알 수 없음' 응답 옵션 사용
* 다양한 시드를 통한 QA 반복 진행(3만 개 샘플 중 2개 정도만 차이)
* vLLM을 이용한 코드로 추론 속도 개선

---

## 5. 결론 및 느낀점

대회를 진행하며 LLM에 대한 이해가 깊어졌으며, 태형 박사님과의 협력으로 다양한 아이디어를 얻어 최종 2등을 수상했습니다. 프롬프트 구성과 few-shot 적용의 중요성을 인지했으며, 팀 협력을 통해 전략을 효과적으로 발전시킬 수 있었습니다. 앞으로 더 많은 LLM 활용 전략을 연구할 계획입니다.

---

## 🎉 최종 성과

* **최종 2등(최우수상)** 수상
* 다양한 마스킹 전략과 추론 최적화를 통한 높은 정확도 달성
* Llama-3.1-8B-Instruct 모델 활용 능력 및 편향 대응 전략 습득
